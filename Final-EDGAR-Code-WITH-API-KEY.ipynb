{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = ['Apple', 'Facebook']\n",
    "years = ['2017', '2016', '2015']\n",
    "\n",
    "filing_type = '10-k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! We were able to find 2 of your queries in the S&P 500\n",
      "We found: ['Apple Inc.', 'Facebook, Inc.'] in the S&P 500\n",
      "Error, There is no XBRL file for FB on 2016-04-27\n",
      "Error, There is no XBRL file for FB on 2015-02-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Kanishka Ramanan\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_Stock\n",
      "{'AAPL': {'2017-11-03': [174.25, 168.11, 163.05], '2016-10-26': [112.48224004304, 116.18645077821, 115.07617010693], '2015-10-28': [115.95126768775, 110.19843784645, 109.43844861992]}, 'FB': {'2017-02-03': [132.06, 130.84, 132.18]}}\n",
      "One_Day\n",
      "{'AAPL': [['2017-11-03', '2016-10-26', '2015-10-28'], [-6.43, 2.31, -5.62]], 'FB': [['2017-02-03'], [0.09]]}\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import bs4\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Defining Functions\n",
    "\n",
    "# Checking Companies\n",
    "def company_check(company_list):\n",
    "    key_path = os.path.join('Ticker_and_CIK', 'Key.csv')\n",
    "    key_df = pd.read_csv(key_path)\n",
    "    key_dict = {}\n",
    "\n",
    "    for query in range(len(company_list)):\n",
    "        try:\n",
    "            company_df = key_df[key_df['Company'].str.contains(company_list[query].title())]\n",
    "            key_dict[company_df.iloc[0, 1]] = [company_df.iloc[0, 0], company_df.iloc[0, 2]]\n",
    "        except IndexError:\n",
    "            print(f\"{company_list[query]} could not be found\")\n",
    "    if key_dict == {}:\n",
    "        print (\"Whoops, none of your companies were on the S&P 500. Please try again!\")\n",
    "    else:\n",
    "        print (f\"Success! We were able to find {len(key_dict.keys())} of your queries in the S&P 500\")\n",
    "        print (f\"We found: {list(key_dict.keys())} in the S&P 500\")\n",
    "        return key_dict\n",
    "\n",
    "    \n",
    "# Obtaining Financials from the SEC\n",
    "def fetch_document_links(cells, year):\n",
    "    doc_link = 'https://www.sec.gov' + cells[1].a['href']\n",
    "#     print(doc_link)\n",
    "    # Obtain HTML for document page\n",
    "    doc_resp = requests.get(doc_link)\n",
    "    doc_str = doc_resp.text\n",
    "    # Find the XBRL link\n",
    "    soup_doc = BeautifulSoup(doc_str, 'html.parser')\n",
    "    table_tag_doc = soup_doc.find('table', class_='tableFile', summary='Data Files')\n",
    "    rows_doc = table_tag_doc.find_all('tr')\n",
    "    for row_doc in rows_doc:\n",
    "        cells_doc = row_doc.find_all('td')\n",
    "        if len(cells_doc) > 3:\n",
    "                if 'XML' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href']\n",
    "                elif 'INS' in cells_doc[3].text:\n",
    "                    return 'https://www.sec.gov' + cells_doc[2].a['href'] \n",
    "                \n",
    "def fetch_financial_data(ticker, tag_list, as_of_dates, financial_dict):\n",
    "    row_num = 0\n",
    "    for tag in tag_list:\n",
    "        if 'schemaref' in tag.name:\n",
    "            ignored_href_index = len(ticker) + 1\n",
    "            as_of_date = tag['xlink:href'][ignored_href_index:(ignored_href_index+8)]\n",
    "            as_of_dates.append(as_of_date)\n",
    "            \n",
    "        if tag.name.find('us-gaap:') != -1:\n",
    "            try: \n",
    "                if float(tag.text) > 0:\n",
    "                    i = [f'{tag.name}', tag.text, tag['contextref']]\n",
    "                    financial_dict[f'{row_num}'] = i\n",
    "                    row_num = row_num + 1\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            \n",
    "# Unmodified Base Code found at https://www.codeproject.com/Articles/1227765/Parsing-XBRL-with-Python\n",
    "def financial_scraper(key_dict, filing_type, published_date_dict, as_of_date_dict, agg_financial_dict):\n",
    "    #Looping through Companies in List\n",
    "    for companies_found in range(len(key_dict.keys())):\n",
    "        # Obtaining Ticker Symbol\n",
    "        company_name = list(key_dict.keys())[companies_found]\n",
    "        ticker = key_dict.get(company_name)[0]\n",
    "\n",
    "        cik = key_dict.get(company_name)[1]\n",
    "        dateb = f'{years[0]}-12-31'\n",
    "\n",
    "        # Obtain HTML for search page\n",
    "        base_url = \"https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type={}&dateb={}\"\n",
    "        edgar_resp = requests.get(base_url.format(cik, filing_type, dateb))\n",
    "        edgar_str = edgar_resp.text\n",
    "\n",
    "        doc_links = []\n",
    "        published_dates = []\n",
    "        as_of_dates = []\n",
    "\n",
    "        # Find the document link\n",
    "        soup = BeautifulSoup(edgar_str, 'html.parser')\n",
    "        table_tag = soup.find('table', class_='tableFile2')\n",
    "        rows = table_tag.find_all('tr')\n",
    "        \n",
    "        all_years_dict = {}\n",
    "        \n",
    "        for year in years:\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) > 3:\n",
    "                    if year in cells[3].text:\n",
    "                        published_date = cells[3].text\n",
    "                        published_dates.append(published_date)\n",
    "\n",
    "                        try:\n",
    "                            xbrl_link = fetch_document_links(cells, year)\n",
    "                        except AttributeError:\n",
    "                            print(f'Error, There is no XBRL file for {ticker} on {published_date}')\n",
    "                            break\n",
    "                        # Obtain XBRL text from document\n",
    "                        xbrl_resp = requests.get(xbrl_link)\n",
    "                        xbrl_str = xbrl_resp.text\n",
    "\n",
    "                        # Find and print stockholder's equity\n",
    "                        soup = BeautifulSoup(xbrl_str, 'lxml')\n",
    "                        tag_list = soup.find_all()\n",
    "\n",
    "                        financial_dict = {}\n",
    "\n",
    "                        fetch_financial_data(ticker, tag_list, as_of_dates, financial_dict)\n",
    "                 \n",
    "                        all_years_dict[f'{published_date}'] = financial_dict\n",
    "                    \n",
    "        published_date_dict[ticker] = published_dates\n",
    "        as_of_date_dict[ticker] = as_of_dates\n",
    "        agg_financial_dict[ticker] = all_years_dict\n",
    "        \n",
    "        \n",
    "        \n",
    "# Finding Entries already Saved as Variable\n",
    "def find_entries(as_of_date_dict, published_date_dict, agg_financial_dict, journal_entry_name_dict):\n",
    "    all_financial_dict = {}\n",
    "    \n",
    "    for companies_found in range(len(published_date_dict.keys())):\n",
    "        ticker = list(published_date_dict.keys())[companies_found]\n",
    "\n",
    "        comp_curr_ratio_dict = {}\n",
    "        comp_per_change_dict = {}\n",
    "        comp_bvps_dict = {}\n",
    "        comp_eps_dict = {}\n",
    "        comp_week_change_dict = {}\n",
    "        comp_month_change_dict = {}\n",
    "        comp_stock_price_dict = {}\n",
    "        \n",
    "        comp_financials_dict = {}\n",
    "\n",
    "        for date_index in range(len(as_of_date_dict[ticker])):\n",
    "       \n",
    "            df = pd.DataFrame.from_dict(agg_financial_dict[ticker][(published_date_dict[ticker][date_index])], orient = 'index')\n",
    "            date_index_financials_df = {}\n",
    "            \n",
    "            for entry in journal_entry_name_dict.keys():\n",
    "                c_assets_df = df[df[0] == entry]\n",
    "                example = find_entry(as_of_date_dict, ticker, date_index, c_assets_df, entry)\n",
    "           \n",
    "                date_index_financials_df[example[0].values[0]] = int(example[1].values[0]) \n",
    "            comp_financials_dict[published_date_dict[ticker][date_index]] = date_index_financials_df\n",
    "        all_financial_dict[ticker] = comp_financials_dict\n",
    "    return all_financial_dict\n",
    "            \n",
    "def find_entry(as_of_date_dict, ticker, date_index, c_assets_df, entry):\n",
    "    \n",
    "    test_date = as_of_date_dict[ticker][date_index]\n",
    "    y = test_date [0:4]\n",
    "    m = test_date [4:6]\n",
    "    d = test_date [6:8]\n",
    "    \n",
    "    year_check = int(y) + 1\n",
    "    \n",
    "    quarter_list = ['Q4', 'Q3', \"Q2\", \"Q1\"]\n",
    "    context_ref = c_assets_df[2]\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    if len(context_ref) == 1:\n",
    "        # Only one entry\n",
    "        test_df = test_df.append(c_assets_df)\n",
    "        print('Only 1 entry')\n",
    "    elif len(context_ref) == 0:\n",
    "        print(f'Error, {ticker} has no entries for {entry} on {test_date}')\n",
    "        \n",
    "    else:\n",
    "        while year_check >= (int(y)-1):\n",
    "            year_check_df = c_assets_df[context_ref.str.contains(f'{year_check}')]\n",
    "            \n",
    "            if len(year_check_df) == 1:\n",
    "                # Only 1 entry for the year\n",
    "                test_df = test_df.append(year_check_df)\n",
    "#                 print(test_df)\n",
    "#                 print('Only 1 entry of that year')\n",
    "                break\n",
    "            else: \n",
    "                date_formats = [f'{year_check}{m}{d}', f'{year_check}-{m}-{d}', f'{m.lstrip(\"0\")}_{d.lstrip(\"0\")}_{year_check}']\n",
    "\n",
    "                for item in date_formats:\n",
    "                    # Check through yyyymmdd, yyyy-mm-dd, and mm_dd_yyyy\n",
    "                    if len(c_assets_df[context_ref.str.contains(f'{item}')]) == 1:\n",
    "                        # Only 1 entry\n",
    "                        test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{item}')])\n",
    "#                         print(test_df)\n",
    "#                         print(f'Context Ref uses {item} format')\n",
    "                        break\n",
    "                    elif len(c_assets_df[context_ref.str.contains(f'{item}')]) > 1:\n",
    "                        # Multiple Entries (usually in case of stockholder equity)\n",
    "                        stock_holder_df = c_assets_df[context_ref.str.contains(f'{item}')]\n",
    "                        stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                        # Take Max Value given\n",
    "                        test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[[0]]\n",
    "#                         print(test_df)\n",
    "#                         print(f'Context Ref uses {item} format, multiple entries')\n",
    "                        break\n",
    "                else:\n",
    "                    for quarter in quarter_list:\n",
    "                        # Check through q#yyyy\n",
    "                        if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) > 0:\n",
    "                            if len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) == 1:\n",
    "                                test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')])\n",
    "#                                 print(test_df)\n",
    "#                                 print(f'Context Ref uses {quarter}{year_check} format')\n",
    "                                break\n",
    "                            elif len(c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]) > 1:\n",
    "                                # Multiple Entries (usually in case of stockholder equity)\n",
    "                                stock_holder_df = c_assets_df[context_ref.str.contains(f'{quarter}{year_check}')]\n",
    "                                stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                                test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[[0]]\n",
    "#                                 print(test_df)\n",
    "                                break\n",
    "                        elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) > 0:\n",
    "                            if len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) == 1:\n",
    "                                test_df = test_df.append(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')])\n",
    "#                                 print(test_df)\n",
    "#                                 print(f'Context Ref uses {year_check}{quarter} format')\n",
    "                                break\n",
    "                            elif len(c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]) > 1:\n",
    "                                # Multiple Entries (usually in case of stockholder equity)\n",
    "                                stock_holder_df = c_assets_df[context_ref.str.contains(f'{year_check}{quarter}')]\n",
    "                                stock_holder_df[1] = stock_holder_df[1].map(int)\n",
    "                                test_df = stock_holder_df[stock_holder_df[1] == stock_holder_df[1].max()].iloc[[0]]\n",
    "#                                 print(test_df)\n",
    "                                break\n",
    "                if len(test_df) == 0:\n",
    "                    year_check = year_check - 1\n",
    "                else:\n",
    "                    year_check = int(y) - 2\n",
    "#         else:\n",
    "#             print(f\" I'm sorry, {ticker} does not use a proper ContextRef format for {entry} on {test_date} \")\n",
    "    return test_df\n",
    "\n",
    "def fetch_stock_price(html_table_dict, quandl_api_key):\n",
    "    \n",
    "    all_stock_price_dict = {}\n",
    "\n",
    "    # Loop through Companies\n",
    "    for comp in range(len(html_table_dict)):\n",
    "        comp_stock_price_dict = {}\n",
    "        ticker = list(html_table_dict.keys())[comp]\n",
    "\n",
    "        api_link = f'https://www.quandl.com/api/v3/datasets/WIKI/{ticker}.json?api_key={quandl_api_key}'\n",
    "        response = requests.get(api_link)\n",
    "        json_data = json.loads(response.text)\n",
    "\n",
    "        for date in list(html_table_dict[ticker].keys()):\n",
    "            date_stock_price_list = []\n",
    "\n",
    "            for day in range(len(json_data['dataset']['data'])):\n",
    "                if date in json_data['dataset']['data'][day]:\n",
    "                    date_stock_price_list.extend((json_data['dataset']['data'][day-1][11],\\\n",
    "                                                  json_data['dataset']['data'][day+1][11],\\\n",
    "                                                  json_data['dataset']['data'][day+5][11]))\n",
    "            \n",
    "            comp_stock_price_dict[date] = date_stock_price_list\n",
    "        all_stock_price_dict[ticker] = comp_stock_price_dict\n",
    "    \n",
    "    return all_stock_price_dict\n",
    "\n",
    "def rearrange_table(html_table_dict, journal_entry_name_dict):\n",
    "    rearranged_table_dict = {}\n",
    "    for ticker in html_table_dict.keys():\n",
    "        \n",
    "        rearranged_entry_name_dict = {}\n",
    "        for entry_name in journal_entry_name_dict.keys():\n",
    "            \n",
    "            rearranged_entry_list = []\n",
    "            for date in html_table_dict[ticker].keys():\n",
    "                if entry_name in html_table_dict[ticker][date]:\n",
    "                    rearranged_entry_list.append(html_table_dict[ticker][date][entry_name])\n",
    "                else:\n",
    "                    rearranged_entry_list.append(None)\n",
    "            rearranged_entry_name_dict[entry_name] = rearranged_entry_list\n",
    "            rearranged_table_dict[ticker] = rearranged_entry_name_dict\n",
    "    \n",
    "    return rearranged_table_dict\n",
    "\n",
    "def one_day_stock_movement(all_stock_price_dict):\n",
    "    one_day_stock_movement_dict = {}\n",
    "    for ticker in all_stock_price_dict.keys():\n",
    "        \n",
    "        date_list = []\n",
    "        day_move_list = []\n",
    "        \n",
    "        for date in all_stock_price_dict[ticker].keys():\n",
    "            price_movement = (all_stock_price_dict[ticker][date][2] / all_stock_price_dict[ticker][date][0])\n",
    "            day_move_list.append(round(((price_movement-1)* 100), 2))\n",
    "            date_list.append(date)\n",
    "        one_day_stock_movement_dict[ticker] = [date_list, day_move_list]\n",
    "    \n",
    "    return one_day_stock_movement_dict\n",
    "\n",
    "def find_current_ratio(all_financials_dict):\n",
    "    all_current_ratio_dict = {}\n",
    "    for ticker in all_financials_dict.keys():\n",
    "\n",
    "        date_list = []\n",
    "        current_ratio_list = []\n",
    "\n",
    "        for date in all_financials_dict[ticker].keys():\n",
    "            for entry_name in all_financials_dict[ticker][date].keys():\n",
    "\n",
    "                if entry_name == 'us-gaap:assetscurrent':\n",
    "                    current_assets = all_financials_dict[ticker][date][entry_name]\n",
    "\n",
    "                elif entry_name == 'us-gaap:liabilitiescurrent':\n",
    "                    current_liabilities = all_financials_dict[ticker][date][entry_name]\n",
    "                    current_ratio = round(current_assets / current_liabilities, 2)\n",
    "                    current_ratio_list.append(current_ratio)\n",
    "                    \n",
    "            date_list.append(date)\n",
    "        all_current_ratio_dict[ticker] = [date_list, current_ratio_list]\n",
    "\n",
    "    return all_current_ratio_dict\n",
    "\n",
    "    \n",
    "# Defining Date Dictionaries\n",
    "published_date_dict = {}\n",
    "as_of_date_dict = {}\n",
    "agg_financial_dict = {}\n",
    "\n",
    "journal_entry_name_dict = {'us-gaap:cashandcashequivalentsatcarryingvalue': 'Cash', 'us-gaap:assetscurrent': 'Current Assets', 'us-gaap:assets': 'Assets',\\\n",
    "  'us-gaap:liabilitiescurrent': \"Current Liabilities\", 'us-gaap:liabilities': 'Liabilities', 'us-gaap:stockholdersequity': 'Stockholders Equity'}\n",
    "\n",
    "quandl_api_key = 'C1LNyzrxv1pvjkP955ua'\n",
    "\n",
    "# Running Functions\n",
    "key_dict = company_check(company_list)\n",
    "financial_scraper(key_dict, filing_type, published_date_dict, as_of_date_dict, agg_financial_dict)   \n",
    "all_financials_dict = find_entries(as_of_date_dict, published_date_dict, agg_financial_dict, journal_entry_name_dict)\n",
    "# print(\"HTML\")\n",
    "# print(all_financials_dict)\n",
    "rearranged_table_dict = rearrange_table(all_financials_dict, journal_entry_name_dict)\n",
    "# print(\"Rearrange\")\n",
    "# print(rearranged_table_dict)\n",
    "all_stock_price_dict = fetch_stock_price(all_financials_dict, quandl_api_key)\n",
    "print(\"All_Stock\")\n",
    "print(all_stock_price_dict)\n",
    "one_day_stock_movement_dict = one_day_stock_movement(all_stock_price_dict)\n",
    "print(\"One_Day\")\n",
    "print(one_day_stock_movement_dict)  \n",
    "current_ratio = find_current_ratio(all_financials_dict)\n",
    "# print(current_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
